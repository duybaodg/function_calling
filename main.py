from openai import OpenAI
import json
open_api_key="EMPTY"
openai_base="http://192.168.88.5:1234/v1"

client = OpenAI(api_key=open_api_key,
                base_url=openai_base)

# 1. Define a list of callable tools for the model

tools = [
    {
        "type": "function",
        "name": "get_horoscope",
        "description": "Get today's horoscope for an astrological sign.",
        "parameters": {
            "type": "object",
            "properties": {
                "sign": {
                    "type": "string",
                    "description": "An astrological sign like Taurus or Aquarius",
                },
            },
            "required": ["sign"],
        },
    },
]
def get_horoscope(sign):
    return f"{sign}: Next Tuesday you will befriend a baby otter."
# Create a running input list we will add to over time

input_list = """[{"role": "user", "content": "What is my horoscope? I am an Aquarius."}
]"""
# 2. Prompt the model with tools defined
response = client.responses.create(
    model="gpt-5",
    tools=tools,
    input=input_list,
)
# Save function call outputs for subsequent requests
#print(response.output)
#input_list+=response.output
for item in response.output:
    if item.type == "function_call":
        if item.name == "get_horoscope":
            # Execute the function logic for get_horoscope
            horoscope = get_horoscope(json.load(item.arguments))
            # 4. Provide function call results to the model
            input_list.append({
                "type":"function_call_output",
                "call_id":item.call_id,
                "output": json.dumps({
                    "horoscope": horoscope
                })
            })
print("Final result")
print(input_list)

response = client.responses.create(
    model="gpt-5",
    instructions="Respond only with a horoscope generated by a tool.",
    tools=tools,
    input=input_list,
)
# 5. The model should be able to give a response!
print("Final output")
print(response.model_dump_json(indent=2))
print("\n" + response.output_text)

